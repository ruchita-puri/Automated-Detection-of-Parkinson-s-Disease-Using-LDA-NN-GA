{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Bql6jt9INfwZBabqtU4jqVKPf-tVjhr-",
      "authorship_tag": "ABX9TyP1POYoWHnETJciUMZmKoQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruchita-puri/Automated-Detection-of-Parkinson-s-Disease-Using-LDA-NN-GA/blob/main/DB4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import zscore\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "#from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n"
      ],
      "metadata": {
        "id": "xMylT98VJV77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Train Data \n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DB4_Train.csv\")\n",
        "X_first = numpy.array(df)\n",
        "X_train = numpy.delete(X_first, 27, 1)\n",
        "X_withlabels = numpy.delete(X_train, 0,1)\n",
        "print(\"X_with contains 26 input features and class label but not with patient id\", X_withlabels.shape)               \n",
        "X = numpy.delete(X_withlabels, 26, 1)\n",
        "print(\"X contains 26 input features only and there is no output label\", X.shape)\n",
        "Y = X_withlabels[: ,26]\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "oQSuFb6a2XVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc74f6bf-7c0d-4263-d3d5-f5c2b4de25f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_with contains 26 input features and class label but not with patient id (832, 27)\n",
            "X contains 26 input features only and there is no output label (832, 26)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code extracts vowel 'u' phonations**"
      ],
      "metadata": {
        "id": "OVlBG7iOnhmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Vowel \"u\" Phonations.\n",
        "i=1\n",
        "indices = 2 #if you change this to 1 and increment to 27, we will get Vowel \"o\" Dataset\n",
        "increment=28\n",
        "while i<=31:\n",
        "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    increment = increment+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y = X_train_withlabels[:, 26]\n",
        "X = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(indices)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4q_WTHengJ9",
        "outputId": "24e6f09f-384b-43ab-c690-58ee677d8e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,)\n",
            "(32, 27)\n",
            "(32, 26)\n",
            "(32,)\n",
            "[  2  28  54  80 106 132 158 184 210 236 262 288 314 340 366 392 418 444\n",
            " 470 496 522 548 574 600 626 652 678 704 730 756 782 808]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code extracts vowel 'o' phonations**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VxVjBIh4n2Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Vowel \"o\" Phonations.\n",
        "i=1\n",
        "indices = 1 #if you change this to 1 and increment to 27, we will get Vowel \"o\" Dataset\n",
        "increment=27\n",
        "while i<=31:\n",
        "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    increment = increment+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y = X_train_withlabels[:, 26]\n",
        "X = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(indices)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVB2fO_Gn5TV",
        "outputId": "877091c9-0701-40cc-8694-3c186a6e24f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,)\n",
            "(32, 27)\n",
            "(32, 26)\n",
            "(32,)\n",
            "[  1  27  53  79 105 131 157 183 209 235 261 287 313 339 365 391 417 443\n",
            " 469 495 521 547 573 599 625 651 677 703 729 755 781 807]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below code extracts vowel 'a' phonations**"
      ],
      "metadata": {
        "id": "ugldAUB9oSW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Vowel \"a\" Dataset\n",
        "i=1\n",
        "indices = 0 #if you change this to 1 and increment to 27, we will get Vowel \"o\" Dataset\n",
        "increment=26\n",
        "while i<=31:\n",
        "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    increment = increment+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y = X_train_withlabels[:, 26]\n",
        "X = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvexmYH_op4l",
        "outputId": "e1cd65d5-bb29-4d0d-d494-824417fc1cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,)\n",
            "(32, 27)\n",
            "(32, 26)\n",
            "(32,)\n",
            "[  0  26  52  78 104 130 156 182 208 234 260 286 312 338 364 390 416 442\n",
            " 468 494 520 546 572 598 624 650 676 702 728 754 780 806]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below Code is for Genetic Algorithm Code.**"
      ],
      "metadata": {
        "id": "Q_XGqlflo2RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import itertools\n",
        "random.seed(1)\n",
        "\n",
        "\n",
        "X_Origionl = X\n",
        "y_Origionl = Y\n",
        "\n",
        "x = range(1,101)\n",
        "lda = LDA(n_components=1)\n",
        "X = lda.fit_transform(X_Origionl, y_Origionl)\n",
        "y = y_Origionl\n",
        "paramgrid = {\"hidden_layer_sizes\": list(itertools.combinations(x,2)),\n",
        "             \"solver\" :['lbfgs']\n",
        "            \n",
        "             }\n",
        "print(\"Size: \", len(paramgrid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDNJzH9fo7pO",
        "outputId": "e5dc5888-66d3-4b33-b825-0b64ed6da722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "time_a = time.time()\n",
        "if __name__==\"__main__\":\n",
        "    #pool = Pool(4)\n",
        "    cv = EvolutionaryAlgorithmSearchCV(estimator=MLPClassifier(),\n",
        "                                       params=paramgrid,\n",
        "                                       scoring=\"accuracy\",\n",
        "                                       cv=KFold(n_splits=40),\n",
        "                                       verbose=True,\n",
        "                                       population_size=15,\n",
        "                                       gene_mutation_prob=0.10,\n",
        "                                       tournament_size=3,\n",
        "                                       generations_number=10)\n",
        "                                       #pmap = pool.map)\n",
        "    %time cv.fit(X, y)\n",
        "time_b = time.time()\n",
        "print(\"Time Elapsed =\", time_b-time_a)\n",
        "'''"
      ],
      "metadata": {
        "id": "UCJLocy-F5_W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5be67ce5-75e6-4817-87e5-e198889c5485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntime_a = time.time()\\nif __name__==\"__main__\":\\n    #pool = Pool(4)\\n    cv = EvolutionaryAlgorithmSearchCV(estimator=MLPClassifier(),\\n                                       params=paramgrid,\\n                                       scoring=\"accuracy\",\\n                                       cv=KFold(n_splits=40),\\n                                       verbose=True,\\n                                       population_size=15,\\n                                       gene_mutation_prob=0.10,\\n                                       tournament_size=3,\\n                                       generations_number=10)\\n                                       #pmap = pool.map)\\n    %time cv.fit(X, y)\\ntime_b = time.time()\\nprint(\"Time Elapsed =\", time_b-time_a)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regenerating Results of Table III of the Paper**"
      ],
      "metadata": {
        "id": "xiSxacHB24ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Train Data \n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DB4_Train.csv\")\n",
        "X_first = numpy.array(df)\n",
        "X_train = numpy.delete(X_first, 27, 1)\n",
        "X_withlabels = numpy.delete(X_train, 0,1)\n",
        "print(\"X_with contains 26 input features and class label but not with patient id\", X_withlabels.shape)               \n",
        "X = numpy.delete(X_withlabels, 26, 1)\n",
        "print(\"X contains 26 input features only and there is no output label\", X.shape)\n",
        "Y = X_withlabels[: ,26]\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "kgQRaLT72YmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b798b51d-2174-4715-c40f-646ed4503a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_with contains 26 input features and class label but not with patient id (832, 27)\n",
            "X contains 26 input features only and there is no output label (832, 26)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Vowel \"u\" Phonations.\n",
        "i=1\n",
        "indices = 2 #if you change this to 1 and increment to 27, we will get Vowel \"o\" Dataset\n",
        "increment=28\n",
        "while i<=31:\n",
        "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    increment = increment+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y = X_train_withlabels[:, 26]\n",
        "X = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(indices)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "hop7LuVL7Jhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64ea4a9-6126-4b70-b881-48c19cc3c971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,)\n",
            "(32, 27)\n",
            "(32, 26)\n",
            "(32,)\n",
            "[  2  28  54  80 106 132 158 184 210 236 262 288 314 340 366 392 418 444\n",
            " 470 496 522 548 574 600 626 652 678 704 730 756 782 808]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA(n_components=1)\n",
        "X_new = lda.fit_transform(X, Y)\n",
        "\n",
        "Best_Acc =0\n",
        "TP=0\n",
        "TN=0\n",
        "FP=0\n",
        "FN=0\n",
        "\n",
        "\n",
        "i=0\n",
        "Net_Acc=0\n",
        "while i<=31:\n",
        "\n",
        "    #########Setting Train Test Parts for Each Subject\n",
        "    X_test = X_new[[i]]\n",
        "    X_train = numpy.delete(X_new, i, 0)\n",
        "    Y_train = numpy.delete(Y, i, 0)\n",
        "    Y_test = Y[[i]]\n",
        "\n",
        "\n",
        "    ##############Models Part##############################################\n",
        "    #Model Fiting\n",
        "    # checkpoint\n",
        "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2, 29,),random_state=1)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    # evaluate the model\n",
        "    scores = accuracy_score(Y_test, Y_pred)\n",
        "    \n",
        "    if i<=15:\n",
        "        if scores==1:\n",
        "            TP = TP+1 #This is for evaluationg sensitivity\n",
        "    if i>15:\n",
        "        if scores==1:\n",
        "            TN = TN+1  #This is for evaluating specificity\n",
        "    \n",
        "\n",
        "    if scores==1:\n",
        "        Net_Acc = Net_Acc+1 #This is for evaluationg overall accuracy\n",
        "\n",
        "    i = i+1\n",
        "Acc = (Net_Acc/32)*100\n",
        "FN=16-TP\n",
        "FP=16-TN\n",
        "\n",
        "Best_Acc = Acc\n",
        "print(\"Acc ====================================\", Best_Acc)\n",
        "print(\"Sensitivity =\", (TP/(16))*100)\n",
        "print(\"Specificity =\", (TN/(16))*100)\n",
        "print(\"Mathew Correlation Coefficients MCC=\", (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))))"
      ],
      "metadata": {
        "id": "pLL0ULIx7Yfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787ec8cd-5827-43ce-c58f-b9fcc5b52790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc ==================================== 96.875\n",
            "Sensitivity = 93.75\n",
            "Specificity = 100.0\n",
            "Mathew Correlation Coefficients MCC= 0.9393364366277243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regenerating Results of Table IV**"
      ],
      "metadata": {
        "id": "-_qCP2yG7hvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the data of Training Database\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DB4_Train.csv\")\n",
        "X_first = numpy.array(df)\n",
        "X_train = numpy.delete(X_first, 27, 1)\n",
        "X_withlabels = numpy.delete(X_train, 0,1)\n",
        "print(\"X_with contains 26 input features and class label but not with patient id\", X_withlabels.shape)               \n",
        "X = numpy.delete(X_withlabels, 26, 1)\n",
        "print(\"X contains 26 input features only and there is no output label\", X.shape)\n",
        "Y = X_withlabels[: ,26]\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "gwV4NjLW7nJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8cbf78-2d11-4bba-ef9e-d13b03b88e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_with contains 26 input features and class label but not with patient id (832, 27)\n",
            "X contains 26 input features only and there is no output label (832, 26)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Vowel \"o\" Phonations.\n",
        "i=1\n",
        "indices = 1 #if you change this to 1 and increment to 27, we will get Vowel \"o\" Dataset\n",
        "increment=27\n",
        "while i<=31:\n",
        "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    increment = increment+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y = X_train_withlabels[:, 26]\n",
        "X = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(indices)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "xZur9Qu17szA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d90bf39-0c47-4cca-8986-3773dbdf6cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,)\n",
            "(32, 27)\n",
            "(32, 26)\n",
            "(32,)\n",
            "[  1  27  53  79 105 131 157 183 209 235 261 287 313 339 365 391 417 443\n",
            " 469 495 521 547 573 599 625 651 677 703 729 755 781 807]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA(n_components=1)\n",
        "X_new = lda.fit_transform(X, Y)\n",
        "\n",
        "Best_Acc =0\n",
        "TP=0\n",
        "TN=0\n",
        "FP=0\n",
        "FN=0\n",
        "\n",
        "\n",
        "i=0\n",
        "Net_Acc=0\n",
        "while i<=31:\n",
        "\n",
        "    #########Setting Train Test Parts for Each Subject\n",
        "    X_test = X_new[[i]]\n",
        "    X_train = numpy.delete(X_new, i, 0)\n",
        "    Y_train = numpy.delete(Y, i, 0)\n",
        "    Y_test = Y[[i]]\n",
        "\n",
        "\n",
        "    ##############Models Part##############################################\n",
        "    #Model Fiting\n",
        "    # checkpoint\n",
        "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2, 29,),random_state=1)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    # evaluate the model\n",
        "    scores = accuracy_score(Y_test, Y_pred)\n",
        "    \n",
        "    if i<=15:\n",
        "        if scores==1:\n",
        "            TP = TP+1\n",
        "    if i>15:\n",
        "        if scores==1:\n",
        "            TN = TN+1\n",
        "    \n",
        "\n",
        "    if scores==1:\n",
        "        Net_Acc = Net_Acc+1\n",
        "\n",
        "    i = i+1\n",
        "Acc = (Net_Acc/32)*100\n",
        "FN=16-TP\n",
        "FP=16-TN\n",
        "\n",
        "Best_Acc = Acc\n",
        "print(\"Acc ====================================\", Best_Acc)\n",
        "print(\"Sensitivity =\", (TP/(16))*100)\n",
        "print(\"Specificity =\", (TN/(16))*100)\n",
        "print(\"Mathew Correlation Coefficients MCC=\", (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))))"
      ],
      "metadata": {
        "id": "xYgO39-I7yte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7543581b-95b2-4f0e-d184-8c6f407e01f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc ==================================== 100.0\n",
            "Sensitivity = 100.0\n",
            "Specificity = 100.0\n",
            "Mathew Correlation Coefficients MCC= 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regenerating Results of Table V**"
      ],
      "metadata": {
        "id": "ouULzwMa76Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the data of Training Database\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DB4_Train.csv\")\n",
        "X_first = numpy.array(df)\n",
        "X_train = numpy.delete(X_first, 27, 1)\n",
        "X_withlabels = numpy.delete(X_train, 0,1)\n",
        "print(\"X_with contains 26 input features and class label but not with patient id\", X_withlabels.shape)               \n",
        "X = numpy.delete(X_withlabels, 26, 1)\n",
        "print(\"X contains 26 input features only and there is no output label\", X.shape)\n",
        "Y = X_withlabels[: ,26]\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "9sDYnlmn7nP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffa7011-ef51-4441-abb7-b737822864b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_with contains 26 input features and class label but not with patient id (832, 27)\n",
            "X contains 26 input features only and there is no output label (832, 26)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Vowel \"a\" Dataset\n",
        "i=1\n",
        "indices = 0 #if you change this to 1 and increment to 27, we will get Vowel \"o\" Dataset\n",
        "increment=26\n",
        "while i<=31:\n",
        "    indices = numpy.append(indices, increment)    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    increment = increment+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y = X_train_withlabels[:, 26]\n",
        "X = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(indices)"
      ],
      "metadata": {
        "id": "_n6Da9OU8B4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36785f87-a69d-4a5c-8900-bd8e32287934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32,)\n",
            "(32, 27)\n",
            "(32, 26)\n",
            "(32,)\n",
            "[  0  26  52  78 104 130 156 182 208 234 260 286 312 338 364 390 416 442\n",
            " 468 494 520 546 572 598 624 650 676 702 728 754 780 806]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA(n_components=1)\n",
        "X_new = lda.fit_transform(X, Y)\n",
        "\n",
        "Best_Acc =0\n",
        "TP=0\n",
        "TN=0\n",
        "FP=0\n",
        "FN=0\n",
        "\n",
        "\n",
        "i=0\n",
        "Net_Acc=0\n",
        "while i<=31:\n",
        "\n",
        "    #########Setting Train Test Parts for Each Subject\n",
        "    X_test = X_new[[i]]\n",
        "    X_train = numpy.delete(X_new, i, 0)\n",
        "    Y_train = numpy.delete(Y, i, 0)\n",
        "    Y_test = Y[[i]]\n",
        "\n",
        "\n",
        "    ##############Models Part##############################################\n",
        "    #Model Fiting\n",
        "    # checkpoint\n",
        "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2, 29,),random_state=1)\n",
        "    model.fit(X_train, Y_train)\n",
        "    Y_pred = model.predict(X_test)\n",
        "    # evaluate the model\n",
        "    scores = accuracy_score(Y_test, Y_pred)\n",
        "    \n",
        "    if i<=15:\n",
        "        if scores==1:\n",
        "            TP = TP+1\n",
        "    if i>15:\n",
        "        if scores==1:\n",
        "            TN = TN+1\n",
        "    \n",
        "\n",
        "    if scores==1:\n",
        "        Net_Acc = Net_Acc+1\n",
        "\n",
        "    i = i+1\n",
        "Acc = (Net_Acc/32)*100\n",
        "FN=16-TP\n",
        "FP=16-TN\n",
        "\n",
        "Best_Acc = Acc\n",
        "print(\"Acc ====================================\", Best_Acc)\n",
        "print(\"Sensitivity =\", (TP/(16))*100)\n",
        "print(\"Specificity =\", (TN/(16))*100)\n",
        "print(\"Mathew Correlation Coefficients MCC=\", (TP*TN-FP*FN)/(math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))))"
      ],
      "metadata": {
        "id": "iAebgYBy8C9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a7c503-8dff-4f33-d994-f24f04d383b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc ==================================== 84.375\n",
            "Sensitivity = 87.5\n",
            "Specificity = 81.25\n",
            "Mathew Correlation Coefficients MCC= 0.6888467201936644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regenerating Results of Table VI**"
      ],
      "metadata": {
        "id": "Bx8eHs9z8Our"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Train Data \n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DB4_Train.csv\")\n",
        "X_first = numpy.array(df)\n",
        "X_train = numpy.delete(X_first, 27, 1)\n",
        "X_withlabels = numpy.delete(X_train, 0,1)\n",
        "print(\"X_with contains 26 input features and class label but not with patient id\", X_withlabels.shape)               \n",
        "X = numpy.delete(X_withlabels, 26, 1)\n",
        "print(\"X contains 26 input features only and there is no output label\", X.shape)\n",
        "Y = X_withlabels[: ,26]\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "E9kktSM58PdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1519d2d5-4256-4231-96f5-e4ca04df24cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_with contains 26 input features and class label but not with patient id (832, 27)\n",
            "X contains 26 input features only and there is no output label (832, 26)\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting vowel data from training database\n",
        "i=2\n",
        "indices = numpy.array(range(0, 2))\n",
        "lb = 26\n",
        "ub = 28\n",
        "while i<=32:\n",
        "    indices = numpy.append(indices, range(lb, ub))    #Indices will hold all indices of ist three samples in each subject\n",
        "    i = i+1\n",
        "    lb = lb+26\n",
        "    ub = ub+26\n",
        "print(indices.shape)         #Thus we get 32x3=96 indices of 96 samples. Now extract those samples from X and Y to get a new Training Set\n",
        "#print(indices)\n",
        "X_train_withlabels = X_withlabels[[indices]]\n",
        "print(X_train_withlabels.shape)\n",
        "Y_train = X_train_withlabels[:, 26]\n",
        "X_train = numpy.delete(X_train_withlabels, 26, 1)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "id": "_bhx9DQF8SrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1c70f6-bdda-4ea7-c8a2-ec0ef46ff194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64,)\n",
            "(64, 27)\n",
            "(64, 26)\n",
            "(64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Test Data \n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/DB4_Test.csv\")\n",
        "X_first = numpy.array(df)\n",
        "X_test1 = numpy.delete( X_first,27, 1)\n",
        "X_test_withlabels = numpy.delete(X_test1, 0,1)\n",
        "X_test = numpy.delete( X_test_withlabels,26, 1)\n",
        "print(\"X_with contains 26 input features and class label but not with patient id\", X_test_withlabels.shape)   \n",
        "print(X_test.shape)\n",
        "Y_test = X_test_withlabels[:, 26]\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "id": "SSVkGNya8cEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b93ae0-61cc-42de-d4da-d1bacce7cfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_with contains 26 input features and class label but not with patient id (208, 27)\n",
            "(208, 26)\n",
            "(208,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LDA(n_components=1)\n",
        "X_FS_train = lda.fit_transform(X_train, Y_train)\n",
        "\n",
        "\n",
        "######It is important to note below that we are using LDA model fitted on Training Data and Reduce the testing data then.\n",
        "lda = LDA(n_components=1)\n",
        "X_FS_test = lda.fit(X_train, Y_train).transform(X_test)"
      ],
      "metadata": {
        "id": "52ddttFiV1XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### LOSO on Testing Database##############################\n",
        "\n",
        "Best_Acc=0\n",
        "\n",
        "Net_Acc=0\n",
        "i=1\n",
        "lb=0\n",
        "ub=26\n",
        "while i<=8:\n",
        "\n",
        "    #########Setting Train Test Parts for Each Subject\n",
        "    X_test_subj = X_FS_test[range(lb,ub)]\n",
        "    Y_test_subj = Y_test[range(lb,ub)]\n",
        "    #print(X_test_subj.shape)\n",
        "    #print(Y_test_subj.shape)\n",
        "\n",
        "    ##############Models Part##############################################\n",
        "    #Model Fiting\n",
        "    # checkpoint\n",
        "    ##############Models Part##############################################\n",
        "\n",
        "    model =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2, 29,), random_state=1)\n",
        "    model.fit(X_FS_train, Y_train)\n",
        "    Y_pred = model.predict(X_test_subj)\n",
        "    scores = accuracy_score(Y_test_subj, Y_pred)\n",
        "    if scores>=0.5:\n",
        "        Net_Acc = Net_Acc+1\n",
        "\n",
        "\n",
        "    lb=lb+26\n",
        "    ub=lb+26\n",
        "    i = i+1\n",
        "Acc = (Net_Acc*100)/8\n",
        "\n",
        "Best_Acc = Acc\n",
        "print(\"Best Acc =\", Best_Acc)"
      ],
      "metadata": {
        "id": "vpWQ30-Q81vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70fbe51-a70c-494d-8432-a3fdd04792b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Acc = 100.0\n"
          ]
        }
      ]
    }
  ]
}